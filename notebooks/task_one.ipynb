{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/segnig/Amharic-E-commerce-Data-Extractor/blob/task-1/notebooks/task_one.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "XR5Hwy2OnUEM"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel Title</th>\n",
              "      <th>Channel Username</th>\n",
              "      <th>ID</th>\n",
              "      <th>Message</th>\n",
              "      <th>Date</th>\n",
              "      <th>Media Path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6982</td>\n",
              "      <td>üí•üí•...................................üí•üí•\\n\\nüìåIm...</td>\n",
              "      <td>2025-06-18 06:01:10+00:00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6981</td>\n",
              "      <td>üí•üí•...................................üí•üí•\\n\\nüìå B...</td>\n",
              "      <td>2025-06-16 12:21:00+00:00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6980</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2025-06-16 05:11:57+00:00</td>\n",
              "      <td>data\\photos\\@ZemenExpress_6980.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6979</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2025-06-16 05:11:57+00:00</td>\n",
              "      <td>data\\photos\\@ZemenExpress_6979.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6978</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2025-06-16 05:11:57+00:00</td>\n",
              "      <td>data\\photos\\@ZemenExpress_6978.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Channel Title Channel Username    ID  \\\n",
              "0  Zemen Express¬Æ    @ZemenExpress  6982   \n",
              "1  Zemen Express¬Æ    @ZemenExpress  6981   \n",
              "2  Zemen Express¬Æ    @ZemenExpress  6980   \n",
              "3  Zemen Express¬Æ    @ZemenExpress  6979   \n",
              "4  Zemen Express¬Æ    @ZemenExpress  6978   \n",
              "\n",
              "                                             Message  \\\n",
              "0  üí•üí•...................................üí•üí•\\n\\nüìåIm...   \n",
              "1  üí•üí•...................................üí•üí•\\n\\nüìå B...   \n",
              "2                                                NaN   \n",
              "3                                                NaN   \n",
              "4                                                NaN   \n",
              "\n",
              "                        Date                          Media Path  \n",
              "0  2025-06-18 06:01:10+00:00                                 NaN  \n",
              "1  2025-06-16 12:21:00+00:00                                 NaN  \n",
              "2  2025-06-16 05:11:57+00:00  data\\photos\\@ZemenExpress_6980.jpg  \n",
              "3  2025-06-16 05:11:57+00:00  data\\photos\\@ZemenExpress_6979.jpg  \n",
              "4  2025-06-16 05:11:57+00:00  data\\photos\\@ZemenExpress_6978.jpg  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import etnltk\n",
        "\n",
        "## Importing data   \n",
        "\n",
        "data = pd.read_csv(\"../data/telegram_data.csv\")\n",
        "\n",
        "## Tokenizing data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Drop Null message\n",
        "\n",
        "Remove chat entries where the Message values are null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of chat:  23606\n",
            "Total number of message:  23606\n"
          ]
        }
      ],
      "source": [
        "data_clean = data[data[\"Message\"].notna()]\n",
        "\n",
        "print(\"Total number of chat: \", len(data_clean))\n",
        "\n",
        "print(\"Total number of message: \", len(data_clean[\"Message\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Key Steps & Functions**\n",
        "1. **Imports from `etnltk`**:\n",
        "   - `remove_emojis`: Strips emojis (e.g., üòä ‚Üí \"\").\n",
        "   - `remove_links`: Removes URLs (e.g., `https://example.com` ‚Üí \"\").\n",
        "   - `remove_ethiopic_punct`: Clears Ethiopic punctuation (e.g., `·ç¢` ‚Üí \"\").\n",
        "   - `remove_tags`: Deletes social tags (e.g., `@user` ‚Üí \"\").\n",
        "   - `clean_amharic`: Master function for end-to-end cleaning.\n",
        "\n",
        "2. **Custom Function: `remove_telegram_tags`**:\n",
        "   - Removes hashtags (e.g., `#Amharic` ‚Üí `Amharic`).\n",
        "\n",
        "3. **Pipeline (`text_process`)**:\n",
        "   - Applies cleaning steps sequentially:\n",
        "     1. Remove Telegram hashtags (`#`).\n",
        "     2. Strip emojis.\n",
        "     3. Delete links.\n",
        "     4. Clear Ethiopic punctuation.\n",
        "     5. Remove social tags (`@`, `#`).\n",
        "   - Uses `clean_amharic` with the custom pipeline.\n",
        "\n",
        "4. **Execution**:\n",
        "   - Applies `text_process` to each message in `data_clean[\"Message\"]`.\n",
        "   - Stores cleaned output in `data_clean[\"cleaned_message\"]`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\segni\\AppData\\Local\\Temp\\ipykernel_13808\\3982174370.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_clean[\"cleaned_message\"] = data_clean[\"Message\"].apply(text_process)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel Title</th>\n",
              "      <th>Channel Username</th>\n",
              "      <th>ID</th>\n",
              "      <th>Message</th>\n",
              "      <th>Date</th>\n",
              "      <th>Media Path</th>\n",
              "      <th>cleaned_message</th>\n",
              "      <th>normalized_message</th>\n",
              "      <th>tokenized_meassage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6982</td>\n",
              "      <td>üí•üí•...................................üí•üí•\\n\\nüìåIm...</td>\n",
              "      <td>2025-06-18 06:01:10+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Imitation Volcano Humidifier with LED Light ·â†·ä§...</td>\n",
              "      <td>Imitation Volcano Humidifier with LED Light ·â†·ä§...</td>\n",
              "      <td>[·â†·ä§·àå·ä≠·âµ·à™·ä≠·ã®·àö·à∞·à´, ·àà·â§·âµ, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ·ãã·åã, ·â•·à≠, ·ãç...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6981</td>\n",
              "      <td>üí•üí•...................................üí•üí•\\n\\nüìå B...</td>\n",
              "      <td>2025-06-16 12:21:00+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Baby Carrier ·â†·çà·àà·åâ·âµ ·ä†·âÖ·å£·å´ ·àç·åÖ·ãé·äï ·â†·àù·âæ·âµ ·àõ·ãò·àç ·ã´·àµ·âΩ·àç·ãé·â≥·àç ...</td>\n",
              "      <td>Baby Carrier ·â†·çà·àà·åâ·âµ ·ä†·âÖ·å£·å´ ·àç·åÖ·ãé·äï ·â†·àù·âæ·âµ ·àõ·ãò·àç ·ã´·àµ·âΩ·àç·ãé·â≥·àç ...</td>\n",
              "      <td>[·â†·çà·àà·åâ·âµ, ·ä†·âÖ·å£·å´, ·àç·åÖ·ãé·äï, ·â†·àù·âæ·âµ, ·àõ·ãò·àç, ·ã´·àµ·âΩ·àç·ãé·â≥·àç, ·ãã·åã, ·â•·à≠...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6973</td>\n",
              "      <td>üí•üí•...................................üí•üí•\\n\\nüìåSm...</td>\n",
              "      <td>2025-06-16 05:11:57+00:00</td>\n",
              "      <td>data\\photos\\@ZemenExpress_6973.jpg</td>\n",
              "      <td>Smart Usb Ultrasonic Car And Home Air Humidifi...</td>\n",
              "      <td>Smart Usb Ultrasonic Car And Home Air Humidifi...</td>\n",
              "      <td>[·â†·ä§·àå·ä≠·âµ·à™·ä≠, ·ã®·àö·à∞·à´, ·àà·â§·âµ·äì, ·àà·àò·ä™·äì, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6972</td>\n",
              "      <td>üí•üí•...................................üí•üí•\\n\\nüìåSm...</td>\n",
              "      <td>2025-06-16 05:11:26+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Smart Usb Ultrasonic Car And Home Air Humidifi...</td>\n",
              "      <td>Smart Usb Ultrasonic Car And Home Air Humidifi...</td>\n",
              "      <td>[·â†·ä§·àå·ä≠·âµ·à™·ä≠, ·ã®·àö·à∞·à´, ·àà·â§·âµ·äì, ·àà·àò·ä™·äì, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6970</td>\n",
              "      <td>üí•üí•...................................üí•üí•\\n\\nüìåBa...</td>\n",
              "      <td>2025-06-16 05:09:03+00:00</td>\n",
              "      <td>data\\photos\\@ZemenExpress_6970.jpg</td>\n",
              "      <td>Baby Head Helmet Cotton Walk Safety Hat Breath...</td>\n",
              "      <td>Baby Head Helmet Cotton Walk Safety Hat Breath...</td>\n",
              "      <td>[·ãã·åã, ·â•·à≠, ·ãç·àµ·äï, ·çç·à¨, ·äê·ãç, ·ã´·àà·äï, ·ä†·ãµ·à´·àª, ·àò·åà·äì·äõ·àò·à∞·à®·âµ·ã∞·çã·à≠·àû·àç...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Channel Title Channel Username    ID  \\\n",
              "0   Zemen Express¬Æ    @ZemenExpress  6982   \n",
              "1   Zemen Express¬Æ    @ZemenExpress  6981   \n",
              "9   Zemen Express¬Æ    @ZemenExpress  6973   \n",
              "10  Zemen Express¬Æ    @ZemenExpress  6972   \n",
              "12  Zemen Express¬Æ    @ZemenExpress  6970   \n",
              "\n",
              "                                              Message  \\\n",
              "0   üí•üí•...................................üí•üí•\\n\\nüìåIm...   \n",
              "1   üí•üí•...................................üí•üí•\\n\\nüìå B...   \n",
              "9   üí•üí•...................................üí•üí•\\n\\nüìåSm...   \n",
              "10  üí•üí•...................................üí•üí•\\n\\nüìåSm...   \n",
              "12  üí•üí•...................................üí•üí•\\n\\nüìåBa...   \n",
              "\n",
              "                         Date                          Media Path  \\\n",
              "0   2025-06-18 06:01:10+00:00                                 NaN   \n",
              "1   2025-06-16 12:21:00+00:00                                 NaN   \n",
              "9   2025-06-16 05:11:57+00:00  data\\photos\\@ZemenExpress_6973.jpg   \n",
              "10  2025-06-16 05:11:26+00:00                                 NaN   \n",
              "12  2025-06-16 05:09:03+00:00  data\\photos\\@ZemenExpress_6970.jpg   \n",
              "\n",
              "                                      cleaned_message  \\\n",
              "0   Imitation Volcano Humidifier with LED Light ·â†·ä§...   \n",
              "1   Baby Carrier ·â†·çà·àà·åâ·âµ ·ä†·âÖ·å£·å´ ·àç·åÖ·ãé·äï ·â†·àù·âæ·âµ ·àõ·ãò·àç ·ã´·àµ·âΩ·àç·ãé·â≥·àç ...   \n",
              "9   Smart Usb Ultrasonic Car And Home Air Humidifi...   \n",
              "10  Smart Usb Ultrasonic Car And Home Air Humidifi...   \n",
              "12  Baby Head Helmet Cotton Walk Safety Hat Breath...   \n",
              "\n",
              "                                   normalized_message  \\\n",
              "0   Imitation Volcano Humidifier with LED Light ·â†·ä§...   \n",
              "1   Baby Carrier ·â†·çà·àà·åâ·âµ ·ä†·âÖ·å£·å´ ·àç·åÖ·ãé·äï ·â†·àù·âæ·âµ ·àõ·ãò·àç ·ã´·àµ·âΩ·àç·ãé·â≥·àç ...   \n",
              "9   Smart Usb Ultrasonic Car And Home Air Humidifi...   \n",
              "10  Smart Usb Ultrasonic Car And Home Air Humidifi...   \n",
              "12  Baby Head Helmet Cotton Walk Safety Hat Breath...   \n",
              "\n",
              "                                   tokenized_meassage  \n",
              "0   [·â†·ä§·àå·ä≠·âµ·à™·ä≠·ã®·àö·à∞·à´, ·àà·â§·âµ, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ·ãã·åã, ·â•·à≠, ·ãç...  \n",
              "1   [·â†·çà·àà·åâ·âµ, ·ä†·âÖ·å£·å´, ·àç·åÖ·ãé·äï, ·â†·àù·âæ·âµ, ·àõ·ãò·àç, ·ã´·àµ·âΩ·àç·ãé·â≥·àç, ·ãã·åã, ·â•·à≠...  \n",
              "9   [·â†·ä§·àå·ä≠·âµ·à™·ä≠, ·ã®·àö·à∞·à´, ·àà·â§·âµ·äì, ·àà·àò·ä™·äì, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ...  \n",
              "10  [·â†·ä§·àå·ä≠·âµ·à™·ä≠, ·ã®·àö·à∞·à´, ·àà·â§·âµ·äì, ·àà·àò·ä™·äì, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ...  \n",
              "12  [·ãã·åã, ·â•·à≠, ·ãç·àµ·äï, ·çç·à¨, ·äê·ãç, ·ã´·àà·äï, ·ä†·ãµ·à´·àª, ·àò·åà·äì·äõ·àò·à∞·à®·âµ·ã∞·çã·à≠·àû·àç...  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import Amharic text preprocessing functions from ETNLP (Ethio NLP Toolkit)\n",
        "from etnltk.lang.am.preprocessing import (\n",
        "    remove_emojis,       # Removes emoji characters\n",
        "    remove_links,        # Removes URLs and web addresses\n",
        "    remove_ethiopic_punct,  # Removes Ethiopic punctuation marks\n",
        "    remove_tags          # Removes social tags (@mentions, #hashtags)\n",
        ")\n",
        "from etnltk.lang.am import clean_amharic  # Main Amharic text cleaning function\n",
        "\n",
        "\n",
        "def remove_telegram_tags(text):\n",
        "    \"\"\"Remove Telegram-style hashtags from text while preserving other words\"\"\"\n",
        "    words = text.split()  # Split text into individual words\n",
        "    # Filter out words that start with '#' (hashtags)\n",
        "    words = [word for word in words if not word.startswith(\"#\")] \n",
        "    return \" \".join(words)  # Rejoin remaining words into a string\n",
        "  \n",
        "\n",
        "def text_process(text):\n",
        "    \"\"\"\n",
        "    Process and clean Amharic text using a custom pipeline of cleaning functions.\n",
        "    Returns standardized, cleaned text ready for analysis.\n",
        "    \"\"\"\n",
        "    # Define the sequence of cleaning operations to apply\n",
        "    custom_pipeline = [\n",
        "      remove_telegram_tags,  # First: Remove Telegram hashtags\n",
        "      remove_emojis,        # Then: Remove emoji characters\n",
        "      remove_links,         # Then: Remove web URLs\n",
        "      remove_ethiopic_punct,  # Then: Remove Ethiopic punctuation\n",
        "      remove_tags           # Finally: Remove social tags\n",
        "    ]\n",
        "\n",
        "    # Apply the cleaning pipeline using ETNLP's clean_amharic function\n",
        "    # abbrev=False prevents abbreviation expansion\n",
        "    cleaned_text = clean_amharic(text, abbrev=False, pipeline=custom_pipeline)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "\n",
        "# Apply the text processing function to each message in the DataFrame\n",
        "# Creates new column 'cleaned_message' with processed text\n",
        "data_clean[\"cleaned_message\"] = data_clean[\"Message\"].apply(text_process)\n",
        "\n",
        "# Display the first few rows to verify cleaning worked\n",
        "data_clean.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\segni\\AppData\\Local\\Temp\\ipykernel_13808\\2879761990.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_clean[\"normalized_message\"] = data_clean[\"cleaned_message\"].apply(normalize_labialized)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel Title</th>\n",
              "      <th>Channel Username</th>\n",
              "      <th>ID</th>\n",
              "      <th>Message</th>\n",
              "      <th>Date</th>\n",
              "      <th>Media Path</th>\n",
              "      <th>cleaned_message</th>\n",
              "      <th>normalized_message</th>\n",
              "      <th>tokenized_meassage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6982</td>\n",
              "      <td>üí•üí•...................................üí•üí•\\n\\nüìåIm...</td>\n",
              "      <td>2025-06-18 06:01:10+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Imitation Volcano Humidifier with LED Light ·â†·ä§...</td>\n",
              "      <td>Imitation Volcano Humidifier with LED Light ·â†·ä§...</td>\n",
              "      <td>[·â†·ä§·àå·ä≠·âµ·à™·ä≠·ã®·àö·à∞·à´, ·àà·â§·âµ, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ·ãã·åã, ·â•·à≠, ·ãç...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6981</td>\n",
              "      <td>üí•üí•...................................üí•üí•\\n\\nüìå B...</td>\n",
              "      <td>2025-06-16 12:21:00+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Baby Carrier ·â†·çà·àà·åâ·âµ ·ä†·âÖ·å£·å´ ·àç·åÖ·ãé·äï ·â†·àù·âæ·âµ ·àõ·ãò·àç ·ã´·àµ·âΩ·àç·ãé·â≥·àç ...</td>\n",
              "      <td>Baby Carrier ·â†·çà·àà·åâ·âµ ·ä†·âÖ·å£·å´ ·àç·åÖ·ãé·äï ·â†·àù·âæ·âµ ·àõ·ãò·àç ·ã´·àµ·âΩ·àç·ãé·â≥·àç ...</td>\n",
              "      <td>[·â†·çà·àà·åâ·âµ, ·ä†·âÖ·å£·å´, ·àç·åÖ·ãé·äï, ·â†·àù·âæ·âµ, ·àõ·ãò·àç, ·ã´·àµ·âΩ·àç·ãé·â≥·àç, ·ãã·åã, ·â•·à≠...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6973</td>\n",
              "      <td>üí•üí•...................................üí•üí•\\n\\nüìåSm...</td>\n",
              "      <td>2025-06-16 05:11:57+00:00</td>\n",
              "      <td>data\\photos\\@ZemenExpress_6973.jpg</td>\n",
              "      <td>Smart Usb Ultrasonic Car And Home Air Humidifi...</td>\n",
              "      <td>Smart Usb Ultrasonic Car And Home Air Humidifi...</td>\n",
              "      <td>[·â†·ä§·àå·ä≠·âµ·à™·ä≠, ·ã®·àö·à∞·à´, ·àà·â§·âµ·äì, ·àà·àò·ä™·äì, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6972</td>\n",
              "      <td>üí•üí•...................................üí•üí•\\n\\nüìåSm...</td>\n",
              "      <td>2025-06-16 05:11:26+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Smart Usb Ultrasonic Car And Home Air Humidifi...</td>\n",
              "      <td>Smart Usb Ultrasonic Car And Home Air Humidifi...</td>\n",
              "      <td>[·â†·ä§·àå·ä≠·âµ·à™·ä≠, ·ã®·àö·à∞·à´, ·àà·â§·âµ·äì, ·àà·àò·ä™·äì, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6970</td>\n",
              "      <td>üí•üí•...................................üí•üí•\\n\\nüìåBa...</td>\n",
              "      <td>2025-06-16 05:09:03+00:00</td>\n",
              "      <td>data\\photos\\@ZemenExpress_6970.jpg</td>\n",
              "      <td>Baby Head Helmet Cotton Walk Safety Hat Breath...</td>\n",
              "      <td>Baby Head Helmet Cotton Walk Safety Hat Breath...</td>\n",
              "      <td>[·ãã·åã, ·â•·à≠, ·ãç·àµ·äï, ·çç·à¨, ·äê·ãç, ·ã´·àà·äï, ·ä†·ãµ·à´·àª, ·àò·åà·äì·äõ·àò·à∞·à®·âµ·ã∞·çã·à≠·àû·àç...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Channel Title Channel Username    ID  \\\n",
              "0   Zemen Express¬Æ    @ZemenExpress  6982   \n",
              "1   Zemen Express¬Æ    @ZemenExpress  6981   \n",
              "9   Zemen Express¬Æ    @ZemenExpress  6973   \n",
              "10  Zemen Express¬Æ    @ZemenExpress  6972   \n",
              "12  Zemen Express¬Æ    @ZemenExpress  6970   \n",
              "\n",
              "                                              Message  \\\n",
              "0   üí•üí•...................................üí•üí•\\n\\nüìåIm...   \n",
              "1   üí•üí•...................................üí•üí•\\n\\nüìå B...   \n",
              "9   üí•üí•...................................üí•üí•\\n\\nüìåSm...   \n",
              "10  üí•üí•...................................üí•üí•\\n\\nüìåSm...   \n",
              "12  üí•üí•...................................üí•üí•\\n\\nüìåBa...   \n",
              "\n",
              "                         Date                          Media Path  \\\n",
              "0   2025-06-18 06:01:10+00:00                                 NaN   \n",
              "1   2025-06-16 12:21:00+00:00                                 NaN   \n",
              "9   2025-06-16 05:11:57+00:00  data\\photos\\@ZemenExpress_6973.jpg   \n",
              "10  2025-06-16 05:11:26+00:00                                 NaN   \n",
              "12  2025-06-16 05:09:03+00:00  data\\photos\\@ZemenExpress_6970.jpg   \n",
              "\n",
              "                                      cleaned_message  \\\n",
              "0   Imitation Volcano Humidifier with LED Light ·â†·ä§...   \n",
              "1   Baby Carrier ·â†·çà·àà·åâ·âµ ·ä†·âÖ·å£·å´ ·àç·åÖ·ãé·äï ·â†·àù·âæ·âµ ·àõ·ãò·àç ·ã´·àµ·âΩ·àç·ãé·â≥·àç ...   \n",
              "9   Smart Usb Ultrasonic Car And Home Air Humidifi...   \n",
              "10  Smart Usb Ultrasonic Car And Home Air Humidifi...   \n",
              "12  Baby Head Helmet Cotton Walk Safety Hat Breath...   \n",
              "\n",
              "                                   normalized_message  \\\n",
              "0   Imitation Volcano Humidifier with LED Light ·â†·ä§...   \n",
              "1   Baby Carrier ·â†·çà·àà·åâ·âµ ·ä†·âÖ·å£·å´ ·àç·åÖ·ãé·äï ·â†·àù·âæ·âµ ·àõ·ãò·àç ·ã´·àµ·âΩ·àç·ãé·â≥·àç ...   \n",
              "9   Smart Usb Ultrasonic Car And Home Air Humidifi...   \n",
              "10  Smart Usb Ultrasonic Car And Home Air Humidifi...   \n",
              "12  Baby Head Helmet Cotton Walk Safety Hat Breath...   \n",
              "\n",
              "                                   tokenized_meassage  \n",
              "0   [·â†·ä§·àå·ä≠·âµ·à™·ä≠·ã®·àö·à∞·à´, ·àà·â§·âµ, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ·ãã·åã, ·â•·à≠, ·ãç...  \n",
              "1   [·â†·çà·àà·åâ·âµ, ·ä†·âÖ·å£·å´, ·àç·åÖ·ãé·äï, ·â†·àù·âæ·âµ, ·àõ·ãò·àç, ·ã´·àµ·âΩ·àç·ãé·â≥·àç, ·ãã·åã, ·â•·à≠...  \n",
              "9   [·â†·ä§·àå·ä≠·âµ·à™·ä≠, ·ã®·àö·à∞·à´, ·àà·â§·âµ·äì, ·àà·àò·ä™·äì, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ...  \n",
              "10  [·â†·ä§·àå·ä≠·âµ·à™·ä≠, ·ã®·àö·à∞·à´, ·àà·â§·âµ·äì, ·àà·àò·ä™·äì, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ...  \n",
              "12  [·ãã·åã, ·â•·à≠, ·ãç·àµ·äï, ·çç·à¨, ·äê·ãç, ·ã´·àà·äï, ·ä†·ãµ·à´·àª, ·àò·åà·äì·äõ·àò·à∞·à®·âµ·ã∞·çã·à≠·àû·àç...  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Normalize labialized Amharic characters to their standard forms\n",
        "# Example: Converts variations like '·àè' (labialized ·àà) to regular '·àà'\n",
        "# This ensures consistent text representation for downstream NLP tasks\n",
        "from etnltk.lang.am.normalizer import normalize_labialized\n",
        "\n",
        "# Apply normalization to each cleaned message in the DataFrame\n",
        "# Creates new column 'normalized_message' with standardized characters\n",
        "data_clean[\"normalized_message\"] = data_clean[\"cleaned_message\"].apply(normalize_labialized)\n",
        "\n",
        "# Display sample results to verify normalization\n",
        "data_clean.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenization  - word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\segni\\AppData\\Local\\Temp\\ipykernel_13808\\1600666863.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_clean[\"tokenized_message\"] = data_clean[\"normalized_message\"].apply(word_tokenize)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Channel Title</th>\n",
              "      <th>Channel Username</th>\n",
              "      <th>ID</th>\n",
              "      <th>Message</th>\n",
              "      <th>Date</th>\n",
              "      <th>Media Path</th>\n",
              "      <th>cleaned_message</th>\n",
              "      <th>normalized_message</th>\n",
              "      <th>tokenized_meassage</th>\n",
              "      <th>tokenized_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6982</td>\n",
              "      <td>üí•üí•...................................üí•üí•\\n\\nüìåIm...</td>\n",
              "      <td>2025-06-18 06:01:10+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Imitation Volcano Humidifier with LED Light ·â†·ä§...</td>\n",
              "      <td>Imitation Volcano Humidifier with LED Light ·â†·ä§...</td>\n",
              "      <td>[·â†·ä§·àå·ä≠·âµ·à™·ä≠·ã®·àö·à∞·à´, ·àà·â§·âµ, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ·ãã·åã, ·â•·à≠, ·ãç...</td>\n",
              "      <td>[·â†·ä§·àå·ä≠·âµ·à™·ä≠·ã®·àö·à∞·à´, ·àà·â§·âµ, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ·ãã·åã, ·â•·à≠, ·ãç...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6981</td>\n",
              "      <td>üí•üí•...................................üí•üí•\\n\\nüìå B...</td>\n",
              "      <td>2025-06-16 12:21:00+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Baby Carrier ·â†·çà·àà·åâ·âµ ·ä†·âÖ·å£·å´ ·àç·åÖ·ãé·äï ·â†·àù·âæ·âµ ·àõ·ãò·àç ·ã´·àµ·âΩ·àç·ãé·â≥·àç ...</td>\n",
              "      <td>Baby Carrier ·â†·çà·àà·åâ·âµ ·ä†·âÖ·å£·å´ ·àç·åÖ·ãé·äï ·â†·àù·âæ·âµ ·àõ·ãò·àç ·ã´·àµ·âΩ·àç·ãé·â≥·àç ...</td>\n",
              "      <td>[·â†·çà·àà·åâ·âµ, ·ä†·âÖ·å£·å´, ·àç·åÖ·ãé·äï, ·â†·àù·âæ·âµ, ·àõ·ãò·àç, ·ã´·àµ·âΩ·àç·ãé·â≥·àç, ·ãã·åã, ·â•·à≠...</td>\n",
              "      <td>[·â†·çà·àà·åâ·âµ, ·ä†·âÖ·å£·å´, ·àç·åÖ·ãé·äï, ·â†·àù·âæ·âµ, ·àõ·ãò·àç, ·ã´·àµ·âΩ·àç·ãé·â≥·àç, ·ãã·åã, ·â•·à≠...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6973</td>\n",
              "      <td>üí•üí•...................................üí•üí•\\n\\nüìåSm...</td>\n",
              "      <td>2025-06-16 05:11:57+00:00</td>\n",
              "      <td>data\\photos\\@ZemenExpress_6973.jpg</td>\n",
              "      <td>Smart Usb Ultrasonic Car And Home Air Humidifi...</td>\n",
              "      <td>Smart Usb Ultrasonic Car And Home Air Humidifi...</td>\n",
              "      <td>[·â†·ä§·àå·ä≠·âµ·à™·ä≠, ·ã®·àö·à∞·à´, ·àà·â§·âµ·äì, ·àà·àò·ä™·äì, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ...</td>\n",
              "      <td>[·â†·ä§·àå·ä≠·âµ·à™·ä≠, ·ã®·àö·à∞·à´, ·àà·â§·âµ·äì, ·àà·àò·ä™·äì, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6972</td>\n",
              "      <td>üí•üí•...................................üí•üí•\\n\\nüìåSm...</td>\n",
              "      <td>2025-06-16 05:11:26+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Smart Usb Ultrasonic Car And Home Air Humidifi...</td>\n",
              "      <td>Smart Usb Ultrasonic Car And Home Air Humidifi...</td>\n",
              "      <td>[·â†·ä§·àå·ä≠·âµ·à™·ä≠, ·ã®·àö·à∞·à´, ·àà·â§·âµ·äì, ·àà·àò·ä™·äì, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ...</td>\n",
              "      <td>[·â†·ä§·àå·ä≠·âµ·à™·ä≠, ·ã®·àö·à∞·à´, ·àà·â§·âµ·äì, ·àà·àò·ä™·äì, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Zemen Express¬Æ</td>\n",
              "      <td>@ZemenExpress</td>\n",
              "      <td>6970</td>\n",
              "      <td>üí•üí•...................................üí•üí•\\n\\nüìåBa...</td>\n",
              "      <td>2025-06-16 05:09:03+00:00</td>\n",
              "      <td>data\\photos\\@ZemenExpress_6970.jpg</td>\n",
              "      <td>Baby Head Helmet Cotton Walk Safety Hat Breath...</td>\n",
              "      <td>Baby Head Helmet Cotton Walk Safety Hat Breath...</td>\n",
              "      <td>[·ãã·åã, ·â•·à≠, ·ãç·àµ·äï, ·çç·à¨, ·äê·ãç, ·ã´·àà·äï, ·ä†·ãµ·à´·àª, ·àò·åà·äì·äõ·àò·à∞·à®·âµ·ã∞·çã·à≠·àû·àç...</td>\n",
              "      <td>[·ãã·åã, ·â•·à≠, ·ãç·àµ·äï, ·çç·à¨, ·äê·ãç, ·ã´·àà·äï, ·ä†·ãµ·à´·àª, ·àò·åà·äì·äõ·àò·à∞·à®·âµ·ã∞·çã·à≠·àû·àç...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Channel Title Channel Username    ID  \\\n",
              "0   Zemen Express¬Æ    @ZemenExpress  6982   \n",
              "1   Zemen Express¬Æ    @ZemenExpress  6981   \n",
              "9   Zemen Express¬Æ    @ZemenExpress  6973   \n",
              "10  Zemen Express¬Æ    @ZemenExpress  6972   \n",
              "12  Zemen Express¬Æ    @ZemenExpress  6970   \n",
              "\n",
              "                                              Message  \\\n",
              "0   üí•üí•...................................üí•üí•\\n\\nüìåIm...   \n",
              "1   üí•üí•...................................üí•üí•\\n\\nüìå B...   \n",
              "9   üí•üí•...................................üí•üí•\\n\\nüìåSm...   \n",
              "10  üí•üí•...................................üí•üí•\\n\\nüìåSm...   \n",
              "12  üí•üí•...................................üí•üí•\\n\\nüìåBa...   \n",
              "\n",
              "                         Date                          Media Path  \\\n",
              "0   2025-06-18 06:01:10+00:00                                 NaN   \n",
              "1   2025-06-16 12:21:00+00:00                                 NaN   \n",
              "9   2025-06-16 05:11:57+00:00  data\\photos\\@ZemenExpress_6973.jpg   \n",
              "10  2025-06-16 05:11:26+00:00                                 NaN   \n",
              "12  2025-06-16 05:09:03+00:00  data\\photos\\@ZemenExpress_6970.jpg   \n",
              "\n",
              "                                      cleaned_message  \\\n",
              "0   Imitation Volcano Humidifier with LED Light ·â†·ä§...   \n",
              "1   Baby Carrier ·â†·çà·àà·åâ·âµ ·ä†·âÖ·å£·å´ ·àç·åÖ·ãé·äï ·â†·àù·âæ·âµ ·àõ·ãò·àç ·ã´·àµ·âΩ·àç·ãé·â≥·àç ...   \n",
              "9   Smart Usb Ultrasonic Car And Home Air Humidifi...   \n",
              "10  Smart Usb Ultrasonic Car And Home Air Humidifi...   \n",
              "12  Baby Head Helmet Cotton Walk Safety Hat Breath...   \n",
              "\n",
              "                                   normalized_message  \\\n",
              "0   Imitation Volcano Humidifier with LED Light ·â†·ä§...   \n",
              "1   Baby Carrier ·â†·çà·àà·åâ·âµ ·ä†·âÖ·å£·å´ ·àç·åÖ·ãé·äï ·â†·àù·âæ·âµ ·àõ·ãò·àç ·ã´·àµ·âΩ·àç·ãé·â≥·àç ...   \n",
              "9   Smart Usb Ultrasonic Car And Home Air Humidifi...   \n",
              "10  Smart Usb Ultrasonic Car And Home Air Humidifi...   \n",
              "12  Baby Head Helmet Cotton Walk Safety Hat Breath...   \n",
              "\n",
              "                                   tokenized_meassage  \\\n",
              "0   [·â†·ä§·àå·ä≠·âµ·à™·ä≠·ã®·àö·à∞·à´, ·àà·â§·âµ, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ·ãã·åã, ·â•·à≠, ·ãç...   \n",
              "1   [·â†·çà·àà·åâ·âµ, ·ä†·âÖ·å£·å´, ·àç·åÖ·ãé·äï, ·â†·àù·âæ·âµ, ·àõ·ãò·àç, ·ã´·àµ·âΩ·àç·ãé·â≥·àç, ·ãã·åã, ·â•·à≠...   \n",
              "9   [·â†·ä§·àå·ä≠·âµ·à™·ä≠, ·ã®·àö·à∞·à´, ·àà·â§·âµ·äì, ·àà·àò·ä™·äì, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ...   \n",
              "10  [·â†·ä§·àå·ä≠·âµ·à™·ä≠, ·ã®·àö·à∞·à´, ·àà·â§·âµ·äì, ·àà·àò·ä™·äì, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ...   \n",
              "12  [·ãã·åã, ·â•·à≠, ·ãç·àµ·äï, ·çç·à¨, ·äê·ãç, ·ã´·àà·äï, ·ä†·ãµ·à´·àª, ·àò·åà·äì·äõ·àò·à∞·à®·âµ·ã∞·çã·à≠·àû·àç...   \n",
              "\n",
              "                                    tokenized_message  \n",
              "0   [·â†·ä§·àå·ä≠·âµ·à™·ä≠·ã®·àö·à∞·à´, ·àà·â§·âµ, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ·ãã·åã, ·â•·à≠, ·ãç...  \n",
              "1   [·â†·çà·àà·åâ·âµ, ·ä†·âÖ·å£·å´, ·àç·åÖ·ãé·äï, ·â†·àù·âæ·âµ, ·àõ·ãò·àç, ·ã´·àµ·âΩ·àç·ãé·â≥·àç, ·ãã·åã, ·â•·à≠...  \n",
              "9   [·â†·ä§·àå·ä≠·âµ·à™·ä≠, ·ã®·àö·à∞·à´, ·àà·â§·âµ·äì, ·àà·àò·ä™·äì, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ...  \n",
              "10  [·â†·ä§·àå·ä≠·âµ·à™·ä≠, ·ã®·àö·à∞·à´, ·àà·â§·âµ·äì, ·àà·àò·ä™·äì, ·àò·àç·ä´·àù, ·àò·ãì·ãõ·äï, ·ã®·àö·à∞·å•, ...  \n",
              "12  [·ãã·åã, ·â•·à≠, ·ãç·àµ·äï, ·çç·à¨, ·äê·ãç, ·ã´·àà·äï, ·ä†·ãµ·à´·àª, ·àò·åà·äì·äõ·àò·à∞·à®·âµ·ã∞·çã·à≠·àû·àç...  "
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tokenize normalized Amharic text into individual words using ETNLP's Amharic tokenizer\n",
        "# This converts each message from a string to a list of words (tokens) for further NLP processing\n",
        "# Example: \"·ãõ·à¨ ·â†·à∞·àõ·ã≠ ·äê·å≠ ·ã∞·àò·äì\" ‚Üí [\"·ãõ·à¨\", \"·â†·à∞·àõ·ã≠\", \"·äê·å≠\", \"·ã∞·àò·äì\"]\n",
        "from etnltk.tokenize.am import word_tokenize\n",
        "\n",
        "# Apply word tokenization to each normalized message in the DataFrame\n",
        "# Creates new column 'tokenized_message' containing lists of word tokens\n",
        "data_clean[\"tokenized_message\"] = data_clean[\"normalized_message\"].apply(word_tokenize)\n",
        "\n",
        "# Display the first 5 rows to verify tokenization results\n",
        "# Shows original message, cleaned/normalized versions, and final tokenization\n",
        "data_clean.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export cleaned and processed Telegram data to CSV file\n",
        "# Includes metadata (Channel, ID, Date) and processed text columns:\n",
        "# - cleaned_message: Raw text after removing noise (emojis, links, etc.)\n",
        "# - normalized_message: Text with standardized Amharic characters  \n",
        "# - tokenized_meassage: Word-tokenized text (Note: Column name contains typo)\n",
        "# Saved to ../data/cleaned_telegram_data.csv for further analysis or modeling\n",
        "\n",
        "data_clean[['Channel Title', 'Channel Username', 'ID', 'Date',\n",
        "       'Media Path', 'cleaned_message', 'normalized_message',\n",
        "       'tokenized_meassage']].to_csv(\"../data/cleaned_telegram_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMhtQ6R7UXXFI6oZcNOrUok",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
